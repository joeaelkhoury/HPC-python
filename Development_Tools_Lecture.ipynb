{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60a86372",
      "metadata": {
        "id": "60a86372"
      },
      "source": [
        "# Development Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408deb07",
      "metadata": {
        "tags": [],
        "id": "408deb07"
      },
      "source": [
        "## Python Virtual Environments\n",
        "\n",
        "Many Unix/Linux systems come preinstalled with python nowadays. However in most systems the installation of new packages requires superuser privileges. Furthermore the version that is provided by the system may not be the one you want or need. If you have multiple projects, depending on different versions of libraries can be even more cumbersome to maintain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb83dddf",
      "metadata": {
        "id": "fb83dddf"
      },
      "source": [
        "### Python venv\n",
        "\n",
        "*More information in the ___[venv docs](https://docs.python.org/3/library/venv.html)___*\n",
        "\n",
        "For this reason python 3 (since version 3.3) comes with the builtin module **venv** that supports having so called *virtual environments*. This allows a user to install the exact version of the libraries they want to use without needing any superuser privileges. Especially when you work together on projects or use different machines this is a very valuable tool.\n",
        "\n",
        "To create a new **venv** simply run the command `python -m venv <directory>` in the local directory *<directory>*. To simplify the usage the `venv` comes with an activation script that sets up the local environment for usage of the `venv`. For this bash's builtin `source` command is used to activate the environment. Consecutive `pip install` commands will install the packages into this local directory. See the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a3d31d",
      "metadata": {
        "id": "e6a3d31d"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/trainvenv\n",
        "\n",
        "# cleanup in case there is already a venv\n",
        "rm -rf venv || true\n",
        "\n",
        "# create a new virtual env in folder 'venv' and update pip & setuptools\n",
        "python -m venv venv --upgrade-deps\n",
        "\n",
        "# activate 'venv'\n",
        "source venv/bin/activate\n",
        "\n",
        "# install all requirements into this environment\n",
        "pip install -r requirements.txt\n",
        "\n",
        "echo \">> Printing python version and installed packages of $PWD/venv\"\n",
        "python --version\n",
        "pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0bf39e2",
      "metadata": {
        "id": "c0bf39e2"
      },
      "source": [
        "The biggest benefit of using this solution is that it already comes bundled with the python standard library (since python 3.3) so it should be available on most systems nowadays."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e081ed",
      "metadata": {
        "id": "f4e081ed"
      },
      "source": [
        "### Pipenv (and virtualenv)\n",
        "\n",
        "*More information in the ___[pipenv docs](https://pipenv.pypa.io/en/latest/)___*\n",
        "\n",
        "`venv` is nice and does its job very well, but if you're coming from the JavaScript/TypeScript world you will most likely want to have a tool such as `npm` to manage your project dependencies.\n",
        "\n",
        "Python does in fact have an equivalent named **Pipenv**. Pipenv internally uses `pip` and the `virtualenv` package, which is a more advanced virtual environment management tool than `venv` behind the scenes as well as other packages to deliver one whole user experience.\n",
        "\n",
        "It solves a lot of problems for the user:\n",
        "- Use one tool to manage the environment instead of multiple (`pip`, `virtualenv`, `Pipfile` ...)\n",
        "- Hashes are used everywhere for security reasons\n",
        "- You can get insight into the dependency graph (`pipenv graph`)\n",
        "- Can automatically load `.env` files\n",
        "\n",
        "#### Installation\n",
        "\n",
        "You can either install `pipenv` using your operating systems tools (e.g. `homebrew`, `chocolatey`, `apt`, `dnf` ...) or, since **pipenv** is itself a python tool, by using `pip` itself:\n",
        "\n",
        "```bash\n",
        "pip install --user pipenv\n",
        "```\n",
        "\n",
        "Omit the `--user` flag if you want to install it system wide.\n",
        "\n",
        "Attention: Depending on your installation (e.g. homebrew) it may be necessary to manually add the user package directory to the `PATH` environment variable to make use of the `pipenv` command.\n",
        "\n",
        "#### Pipfile and package management\n",
        "\n",
        "*pipenv* uses a file called `Pipfile` to describe the environment. Different sections can be defined to shape your virtual environment.\n",
        "\n",
        "See below an example `Pipfile`:\n",
        "\n",
        "```Pipfile\n",
        "[[source]]\n",
        "url = \"https://pypi.org/simple\"\n",
        "verify_ssl = true\n",
        "name = \"pypi\"\n",
        "\n",
        "[packages]\n",
        "numba = \"*\"\n",
        "\n",
        "[dev-packages]\n",
        "pytest = \"*\"\n",
        "faker = \"*\"\n",
        "autopep8 = \"*\"\n",
        "\n",
        "[requires]\n",
        "python_version = \"3.10\"\n",
        "```\n",
        "\n",
        "To create a new virtualenv and an empty `Pipfile` enter the project directory and execute the following command to create both by using the currently active python3 version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b15436",
      "metadata": {
        "tags": [],
        "id": "98b15436"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "# cleanup old stuff\n",
        "rm -f Pipfile Pipfile.lock requirements.txt\n",
        "pipenv --rm >/dev/null 2>/dev/null || true\n",
        "\n",
        "# specify e.g. --python 3.9 if you want to use a specific python version\n",
        "pipenv install\n",
        "\n",
        "echo\n",
        "echo \">>> Resulting Pipfile\"\n",
        "echo\n",
        "cat Pipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182df7ed",
      "metadata": {
        "id": "182df7ed"
      },
      "source": [
        "Please note that this will also create a file called `Pipfile.lock` to track the exact versions and the dependencies of the installed packages.\n",
        "\n",
        "If pipenv recognises an already existing `requirements.txt` file in the local directory it will automatically migrate all the packages into the `Pipfile`. If you want to do this manually you can also just use `pipenv install -r requirements.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c02167",
      "metadata": {
        "id": "a6c02167"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tooling/development/pipenv/requirements.txt\n",
        "numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6fd382",
      "metadata": {
        "id": "fa6fd382"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "# cleanup old stuff\n",
        "rm -f Pipfile Pipfile.lock\n",
        "pipenv --rm >/dev/null 2>/dev/null || true\n",
        "\n",
        "# install again; now with requirements.txt\n",
        "pipenv install\n",
        "\n",
        "echo\n",
        "echo \">>> Resulting Pipfile\"\n",
        "echo\n",
        "cat Pipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15eac461",
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        },
        "id": "15eac461"
      },
      "source": [
        "If there is no preexisting `requirements.txt` file, the packages can just be added to the empty `Pipfile` in the `[packages]` section. Another run of `pipenv install` will then install all packages at once.\n",
        "\n",
        "Alternatively it is also possible to install each package separately by using the syntax `pipenv install <package>`. If pipenv should install a specific version it can be specified by using the corresponding `pip` syntax (e.g. `pipenv install requests~=2.2` or `pipenv install requests>=2.2`).\n",
        "\n",
        "To find out which packages can be upgraded run `pipenv update --outdated`. Please note that this will only show updates if its allowed by the version specifications (e.g. if you pinned a package to a specific version it won't show new versions, since the version is fixed). To actually run the update use `pipenv update`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4987b206",
      "metadata": {
        "id": "4987b206"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "\n",
        "# install an old package and remove the pinning afterwards\n",
        "pipenv install requests==2.1\n",
        "\n",
        "echo \">> Old requests version:\"\n",
        "pipenv run pip list | grep \"requests \"\n",
        "\n",
        "sed -i \"s/==2.1/*/g\" Pipfile\n",
        "\n",
        "# find outdated packages and only list them\n",
        "pipenv update --outdated || true\n",
        "\n",
        "# actually update outdated packages\n",
        "pipenv update\n",
        "\n",
        "echo \">> Resulting requests version:\"\n",
        "pipenv run pip list | grep \"requests \""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b95204",
      "metadata": {
        "id": "25b95204"
      },
      "source": [
        "In order to remove the packages from the virtual environment without altering the `Pipfile` one can run `pipenv uninstall --all` ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "872a0475",
      "metadata": {
        "id": "872a0475"
      },
      "source": [
        "#### Enter the environment\n",
        "\n",
        "To enter the newly built environment run `pipenv shell`. Every command after this will be executed in the subshell and `python` and `pip` executables from the virtual environment will be used.\n",
        "\n",
        "For example a `pip list` will show the packages installed in the virtual environment. Alternatively also try `pipenv graph` to get a dependency graph of all installed packages.\n",
        "\n",
        "```bash\n",
        "$ cd ./tooling/development/pipenv/\n",
        "$ export PIPENV_IGNORE_VIRTUALENVS=1    # to ignore conda env\n",
        "$ export VIRTUAL_ENV=                   # reset the virtual env var\n",
        "$ pipenv shell\n",
        "(pipenv)$ which python\n",
        "~/.local/share/virtualenvs/pipenv-Escyejvs/bin/python\n",
        "(pipenv)$ pip list\n",
        "Package    Version\n",
        "---------- -------\n",
        "mpi4py     3.1.3\n",
        "pip        22.2.2\n",
        "setuptools 65.3.0\n",
        "wheel      0.37.1\n",
        "```\n",
        "\n",
        "You can try this out interactively using a terminal launcher in the jupyter notebook and entering the commands above. To leave the subshell just use `exit`.\n",
        "\n",
        "Instead of opening a shell you can also just execute a command in the environment by using `pipenv run`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bcaeda-93db-4414-b351-17e6908ddf21",
      "metadata": {
        "id": "46bcaeda-93db-4414-b351-17e6908ddf21"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "\n",
        "pipenv run which python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2962aaf",
      "metadata": {
        "id": "f2962aaf"
      },
      "source": [
        "#### Environment and scripts\n",
        "\n",
        "With `pipenv` it is also possible to register certain commands for project management as well as set specific environment variables automatically when entering the virtual env or add small scripts that can be run through pipenv.\n",
        "\n",
        "Run the following code to add a simple script to the Pipfile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6397e0d",
      "metadata": {
        "id": "f6397e0d"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "if grep \"scripts\" ./tooling/development/pipenv/Pipfile > /dev/null\n",
        "then\n",
        "    exit 0\n",
        "fi\n",
        "\n",
        "cat <<EOT >> ./tooling/development/pipenv/Pipfile\n",
        "\n",
        "[scripts]\n",
        "echospam = \"echo I am really a very silly example\"\n",
        "EOT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99529dff-0022-401b-a092-7582e9dc8200",
      "metadata": {
        "id": "99529dff-0022-401b-a092-7582e9dc8200"
      },
      "source": [
        "The command can now be executed by using its name together with the run command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d6a154",
      "metadata": {
        "id": "93d6a154"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "\n",
        "pipenv run echospam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7783db40-8251-4ac9-abb7-1b12e30b85d9",
      "metadata": {
        "tags": [],
        "id": "7783db40-8251-4ac9-abb7-1b12e30b85d9"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/pipenv/\n",
        "# ignore conda env\n",
        "export PIPENV_IGNORE_VIRTUALENVS=1\n",
        "# ignore previously set virtual env var\n",
        "export VIRTUAL_ENV=\n",
        "\n",
        "# remove the created env to cleanup\n",
        "pipenv --rm || true\n",
        "\n",
        "echo \"done.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27e111a-b403-44aa-92bc-8e489b1e2b9f",
      "metadata": {
        "tags": [],
        "id": "f27e111a-b403-44aa-92bc-8e489b1e2b9f"
      },
      "source": [
        "### Poetry\n",
        "\n",
        "__[Poetry](https://python-poetry.org/)__ is a newer tool for python that is similar in its purpose to `pipenv`. It also provides isolation through virtual environments, manages your package dependencies and provides a lock file to lock down the specific versions. Contrary to `pipenv` it uses the more modern `pyproject.toml` file for storing all relevant project settings and a `poetry.lock` file to lock the the package dependencies.\n",
        "\n",
        "In addition to this it can also manage `build` and `publish` operations when developing a package that is going to be distributed.\n",
        "\n",
        "Since this tool wasn't part of the original training material (yet to be updated) we won't go into much more detail at this point but it is a very active project and thus noteworthy. Have a look at it if you are searching for a modern project manager for python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9684a5",
      "metadata": {
        "tags": [],
        "id": "7f9684a5"
      },
      "source": [
        "### Anaconda / Conda\n",
        "\n",
        "*More information in the __[Conda User Guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html)__*\n",
        "\n",
        "**Anaconda** is a software distribution for python and R provided by Anaconda Inc.\n",
        "\n",
        "`conda` itself is actually only the package manager and language-agnostic. The tool was deemed necessary by its creators because they identified certain problems with `pip`, the default python package installer, regarding dependency resolution of packages and security issues. It is mainly used to install matching versions of precompiled scientific libraries for python without going through the trouble of compiling them yourself.\n",
        "\n",
        "If you do not need the full `Anaconda` distribution it is possible to start with the `Miniconda` installer instead and only download the packages that are needed afterwards.\n",
        "\n",
        "#### Channels\n",
        "\n",
        "Conda is similar to other package managers and offers different repositories for installing packages. In conda these repositories are called `channels`. By default conda installs packages from the `default` channel (which is Anaconda Inc's own channel).\n",
        "\n",
        "A very popular conda channel is also the previously mentioned community driven __[conda-forge](https://conda-forge.org/)__ that hosts more recent versions of many packages. There is also another (community) installer named `Miniforge` that has `conda-forge` as main channel per default.\n",
        "\n",
        "##### Channel priority\n",
        "\n",
        "`conda` has a highest to lowest channel priority. This means that if a package is found in a higher priority channel (e.g. `default`) and the package satisfies the installation specifications, the packages in the lower priority channels are ignored. If you want to force the install of a version from a lower priority channel you need to use the additional install switch e.g. `--channel conda-forge`.\n",
        "\n",
        "If you always want to install the newest version available you can also disable the channel priority via `conda config --set channel_priority false`. For more info on channels see __[Managing channels](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html#)__."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc7b0da-0417-4fef-bc1f-0ce633ea3613",
      "metadata": {
        "id": "6cc7b0da-0417-4fef-bc1f-0ce633ea3613"
      },
      "source": [
        "#### Conda init\n",
        "\n",
        "Since `conda` is itself a python program it utilises bash functions to manage the environment before running any commands. Currently there are three known methods of how to do this init step\n",
        "- If you want to automatically enable conda when you login to you account you can use `conda init bash`. This command will add the necessary functions to your bash profile configuration file in `~/.bashrc`\n",
        "- Alternatively this code can be extracted into its own file and sourced whenever `conda` is going to be used (e.g. in a slurm script)\n",
        "- Another method to install the hooks is by using the following command `eval \"$(conda shell.bash hook)\"`\n",
        "\n",
        "Note: Since bash functions are not inherited by subshells we need to call the init functions in each cell before we can (fully) use the conda tool (some commands will work wihtout it). The natural choice for this is the `eval` approach since it always produces the right init code for the specific conda version.\n",
        "\n",
        "In case you want to have a separate conda init script, you can produce this by running the `conda init bash` command with the `--dry-run --verbose` flags and copy the output into a new shell script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26592316-a83f-4632-9c9a-c5e10ace015f",
      "metadata": {
        "id": "26592316-a83f-4632-9c9a-c5e10ace015f"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "conda init bash --dry-run --verbose | grep \"# >>> conda initialize\" -A 100 | grep \"# <<< conda initialize\" -B 100 | sed 's/+//g' > ./tooling/development/conda/conda-init.sh\n",
        "cat ./tooling/development/conda/conda-init.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c1168ef-66d4-4231-822d-5c315935f2b2",
      "metadata": {
        "id": "5c1168ef-66d4-4231-822d-5c315935f2b2"
      },
      "source": [
        "#### Environments\n",
        "\n",
        "`conda` supports having different environments to manage different installations. However it can do a bit more than other virtual environment solutions: with `conda` it is possible to directly install a specific python version for your environment as well as other binary dependencies.\n",
        "\n",
        "After installing `conda` only the `base` environment is usually available. From there you can create other environments, clone environments, install packages and also export environment settings to a file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba5eda8f-3e88-4e67-a07a-15290fddd9b3",
      "metadata": {
        "id": "ba5eda8f-3e88-4e67-a07a-15290fddd9b3"
      },
      "source": [
        "##### Creating a first test environment\n",
        "\n",
        "To create a simple test environment using the latest available python 3.9 and numba the following statement is enough:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fb6977",
      "metadata": {
        "id": "72fb6977"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# hook conda functions\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "conda create -y --name test-env --channel conda-forge python=3.9 numba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fb1f51",
      "metadata": {
        "id": "88fb1f51"
      },
      "source": [
        "After conda has solved the constraints and installed all dependencies the environment can be used from the terminal.\n",
        "\n",
        "Doing the same from e.g. a VSC login node would look like this:\n",
        "\n",
        "```bash\n",
        "skylake user@l42:~$ module load miniconda3\n",
        "skylake user@l42:~$ eval \"$(conda shell.bash hook)\"\n",
        "skylake user@l42:~$ conda create -y --name test-env --channel conda-forge python=3.9 numba\n",
        "... installation ...\n",
        "(base) skylake user@l42:~$ conda activate test-env\n",
        "(test-env) skylake user@l42:~$ python3 --version\n",
        "Python 3.9.16\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f00e7bf2",
      "metadata": {
        "id": "f00e7bf2"
      },
      "source": [
        "##### Environment Files\n",
        "\n",
        "To get reproducible environments it is best to pin the specific versions you are currently using (or want to use). Instead of manually keeping track and specifying them in the terminal whenever you want to create a new environment it is better to use conda environment files instead. This file can then be used by yourself or other people to setup the exact same conda environment.\n",
        "\n",
        "To get a starting point you can simply export the packages from a different active environment (e.g. `base`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3e8dca-dbb3-485f-8860-d844b03dc5f4",
      "metadata": {
        "id": "fb3e8dca-dbb3-485f-8860-d844b03dc5f4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# hook conda functions\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "# activate the base environment since we are in a different one\n",
        "conda activate base\n",
        "\n",
        "# export the `base` environment\n",
        "conda env export --from-history --file ./tooling/development/conda/base-env.yaml\n",
        "\n",
        "echo 'YAML export fo base conda environment:'\n",
        "cat ./tooling/development/conda/base-env.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53322bf4-c717-4cdd-8d25-50450f247949",
      "metadata": {
        "id": "53322bf4-c717-4cdd-8d25-50450f247949"
      },
      "source": [
        "Now lets create our first environment file based on the above output.\n",
        "\n",
        "For this we will just specify a name, installation channels we want to use and a python version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da247636-7331-4908-b3ad-be93edbfa782",
      "metadata": {
        "id": "da247636-7331-4908-b3ad-be93edbfa782"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tooling/development/conda/example-env.yaml\n",
        "name: example\n",
        "channels:\n",
        "  - conda-forge\n",
        "  - defaults\n",
        "dependencies:\n",
        "  - python=3.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5428d2c1-048b-45a2-b06c-917774cfbe7a",
      "metadata": {
        "id": "5428d2c1-048b-45a2-b06c-917774cfbe7a"
      },
      "source": [
        "To make use of the environment file we can now use the command `conda env create` and instead of listing each package in the command we specify the environment file.\n",
        "\n",
        "To customize the installation directory of our new environment we use the `--prefix` flag. If we use a name instead (`--name`) the environment will be installed into the default folder at `~/.conda/envs/<env-name>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1357e9e8-6425-49aa-81a2-fafca72210e2",
      "metadata": {
        "id": "1357e9e8-6425-49aa-81a2-fafca72210e2"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# hook conda functions\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "conda env create \\\n",
        "    --file ./tooling/development/conda/example-env.yaml \\\n",
        "    --prefix ./tooling/development/conda/example-env"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "023379f8-2b2e-47f7-a6c8-332d6ff2582f",
      "metadata": {
        "id": "023379f8-2b2e-47f7-a6c8-332d6ff2582f"
      },
      "source": [
        "To activate an environment that was created at a specific location we need to use the path instead of the name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2465db-00e4-4c0c-91b1-6663ad4109e1",
      "metadata": {
        "id": "8b2465db-00e4-4c0c-91b1-6663ad4109e1"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# hook conda functions\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "conda activate ./tooling/development/conda/example-env\n",
        "\n",
        "which python\n",
        "python --version\n",
        "pip list -v"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84afeedb-0322-48e5-900c-363adc53130b",
      "metadata": {
        "id": "84afeedb-0322-48e5-900c-363adc53130b"
      },
      "source": [
        "To finally clean up and remove the created environments, run the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afaf3bce-089b-423d-a133-fa00bde9ee32",
      "metadata": {
        "id": "afaf3bce-089b-423d-a133-fa00bde9ee32"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# hook conda functions\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "# list existing conda environments\n",
        "conda env list\n",
        "\n",
        "# remove by name\n",
        "conda env remove --name test-env\n",
        "\n",
        "# remove by prefix\n",
        "conda env remove --prefix ./tooling/development/conda/example-env\n",
        "\n",
        "# list envs again to see that the test envs were removed\n",
        "conda env list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5939278f-e615-4d87-b80e-d5cfdc08c2bf",
      "metadata": {
        "tags": [],
        "id": "5939278f-e615-4d87-b80e-d5cfdc08c2bf"
      },
      "source": [
        "## Creating python packages\n",
        "\n",
        "*More information in the docs at __[Packaging and distributing projects](https://packaging.python.org/en/latest/guides/distributing-packages-using-setuptools/)__ and __[Setuptools](https://setuptools.pypa.io/en/latest/userguide/index.html)__*\n",
        "\n",
        "### A minimal package (or: the more traditional way)\n",
        "\n",
        "Creating a basic python package that can be installed with pip from e.g. a repository is fairly easy. All you need for starters is a file called `setup.py` in the root directory of your project. Remember there are lots of other settings so have a look at the __[sampleproject](https://github.com/pypa/sampleproject)__ and the rest of the documentation to get started.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2bd2fde-629a-4d10-ac34-7f6c88559bdf",
      "metadata": {
        "id": "d2bd2fde-629a-4d10-ac34-7f6c88559bdf"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tooling/development/minimal-pkg/setup.py\n",
        "\n",
        "import os\n",
        "\n",
        "# prefer setuptools over the deprecated distutils\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "username = os.getenv('USER', 'dev')\n",
        "\n",
        "setup(\n",
        "    # the name of the package that will be shown everywhere\n",
        "    name=f'python4hpc-{username}',\n",
        "    # package version\n",
        "    version='2023.07.0',\n",
        "    # optional: author of the package\n",
        "    author='VSC',\n",
        "    # optional: author's e-mail\n",
        "    author_email='service@vsc.ac.at',\n",
        "    # when the sources are in a subdirectory e.g. `src/` it is necessary to specify this argument\n",
        "    package_dir={'': 'src'},\n",
        "    # find_packages searches the 'src' directory for subdirs that contain an '__init__.py' file (=packages) and simply adds them\n",
        "    packages=find_packages(where='src'),\n",
        "    # optional: python version requirement e.g. if any features of newer versions are used\n",
        "    python_requires=\">=3.7, <4\",\n",
        "    # optional: setup console scripts\n",
        "    entry_points={  # Optional\n",
        "        \"console_scripts\": [\n",
        "            \"sample=python4hpc.sample:main\",\n",
        "        ],\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2bfd668-dd2f-4f2c-ac8a-075242679b0f",
      "metadata": {
        "id": "d2bfd668-dd2f-4f2c-ac8a-075242679b0f"
      },
      "outputs": [],
      "source": [
        "!pip install ./tooling/development/minimal-pkg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70911442-d347-42c7-b32a-485410383326",
      "metadata": {
        "id": "70911442-d347-42c7-b32a-485410383326"
      },
      "outputs": [],
      "source": [
        "!pip list | grep python4hpc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ff3e12-cf3d-4583-8f6e-4777414b6f97",
      "metadata": {
        "id": "01ff3e12-cf3d-4583-8f6e-4777414b6f97"
      },
      "outputs": [],
      "source": [
        "# we need to use the direct path here since the `bin` dir is most likely not on the PATH of the current user\n",
        "!~/.local/bin/sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76886c3c-7f74-4551-9692-0cdae14e565a",
      "metadata": {
        "id": "76886c3c-7f74-4551-9692-0cdae14e565a"
      },
      "outputs": [],
      "source": [
        "!pip uninstall --yes python4hpc-$USER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f913dcd8-cfd9-4c4b-981e-1a1f994259ec",
      "metadata": {
        "tags": [],
        "id": "f913dcd8-cfd9-4c4b-981e-1a1f994259ec"
      },
      "source": [
        "### Packaging and distributing projects\n",
        "\n",
        "*Taken mostly from __[Packaging Projects](https://packaging.python.org/en/latest/tutorials/packaging-projects/)__*\n",
        "\n",
        "If you're working on a bigger project and you want to share it with other users its also possible to build a package and upload it to the main python package repository: __[PyPi.org](https://pypi.org)__\n",
        "\n",
        "The official packaging tutorial suggests to use a `pyproject.toml` to describe the package instead of a `setup.py` and assumes a `src` directory with packages as subdirectories as default. Most of the arguments are very similar to what we have already seen in the case of the `setup.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36ea06f-4878-45b1-9c13-719e1333d08f",
      "metadata": {
        "tags": [],
        "id": "f36ea06f-4878-45b1-9c13-719e1333d08f"
      },
      "outputs": [],
      "source": [
        "%%writefile ./tooling/development/project-pkg/pyproject.toml\n",
        "\n",
        "[build-system]\n",
        "requires = [\"setuptools>=61.0\"]\n",
        "build-backend = \"setuptools.build_meta\"\n",
        "\n",
        "[project]\n",
        "# don't change this name - will be automatically changed later\n",
        "name = \"python4hpc-pyproject-USERNAME_PLACEHOLDER\"\n",
        "version = \"2023.7.0\"\n",
        "authors = [\n",
        "  { name=\"Example Author\", email=\"author@example.com\" },\n",
        "]\n",
        "description = \"A small example package\"\n",
        "readme = \"README.md\"\n",
        "license = { file=\"LICENSE\" }\n",
        "requires-python = \">=3.7\"\n",
        "classifiers = [\n",
        "    \"Programming Language :: Python :: 3\",\n",
        "    \"License :: OSI Approved :: MIT License\",\n",
        "    \"Operating System :: OS Independent\",\n",
        "]\n",
        "\n",
        "[project.urls]\n",
        "\"Homepage\" = \"https://github.com/pypa/sampleproject\"\n",
        "\"Bug Tracker\" = \"https://github.com/pypa/sampleproject/issues\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd735bb0-fc68-45a0-bbda-5e9929f118cc",
      "metadata": {
        "tags": [],
        "id": "dd735bb0-fc68-45a0-bbda-5e9929f118cc"
      },
      "source": [
        "The following command is only used to replace the default package name with a user specific one so that we don't have name clashes on upload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1465c8a2-17f7-45d4-9972-bd8b46eb27a0",
      "metadata": {
        "tags": [],
        "id": "1465c8a2-17f7-45d4-9972-bd8b46eb27a0"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "sed -i \"s/python4hpc-pyproject-USERNAME_PLACEHOLDER/python4hpc-pyproject-$USER/g\" ./tooling/development/project-pkg/pyproject.toml\n",
        "cat ./tooling/development/project-pkg/pyproject.toml | grep \"name =\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe4bb2c-a465-421e-a7bf-7c579787a970",
      "metadata": {
        "tags": [],
        "id": "efe4bb2c-a465-421e-a7bf-7c579787a970"
      },
      "source": [
        "Now build the project using the `build` tool from the `build` package - this will create a source distribution and a wheel in the `dist` subdirectory of `/tooling/development/project-pkg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10242e18-0559-413e-9d47-3d88a01bf143",
      "metadata": {
        "tags": [],
        "id": "10242e18-0559-413e-9d47-3d88a01bf143"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "cd ./tooling/development/project-pkg\n",
        "python -m build"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ef3c5c-cc9c-47bd-a1c9-d37bd986c900",
      "metadata": {
        "tags": [],
        "id": "61ef3c5c-cc9c-47bd-a1c9-d37bd986c900"
      },
      "source": [
        "For our example package we will use the tool **twine** and upload it to `test.pypi.org`. Please create your own account and an access token if you want to run the following snippets (__[Create an account on TestPyPI](https://test.pypi.org/account/register/)__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeac2adf-0b5d-4d6a-8178-86eeb33418a6",
      "metadata": {
        "id": "aeac2adf-0b5d-4d6a-8178-86eeb33418a6"
      },
      "outputs": [],
      "source": [
        "%%writefile ~/.pypirc\n",
        "[testpypi]\n",
        "  username = __token__\n",
        "  password = <INSERT PYPI TOKEN HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9d06f0-cb9d-43ac-af58-172a9165711c",
      "metadata": {
        "tags": [],
        "id": "db9d06f0-cb9d-43ac-af58-172a9165711c"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/project-pkg\n",
        "python3 -m twine upload --repository testpypi dist/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bf7250-7b60-47b8-8905-22570b8b2b79",
      "metadata": {
        "id": "53bf7250-7b60-47b8-8905-22570b8b2b79"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "pip install -i https://test.pypi.org/simple/ python4hpc-pyproject-$USER\n",
        "echo\n",
        "\n",
        "echo \"List installed packages:\"\n",
        "pip -v list | grep python4hpc-pyproject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c22ad9-1e3e-4115-973b-2cba4363be83",
      "metadata": {
        "id": "c9c22ad9-1e3e-4115-973b-2cba4363be83"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "pip uninstall --yes python4hpc-pyproject-$USER\n",
        "rm -f ./tooling/development/project-pkg/dist/*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12009cb7",
      "metadata": {
        "tags": [],
        "id": "12009cb7"
      },
      "source": [
        "## Apptainer (Singularity)\n",
        "\n",
        "Singularity is an open source container platform, similar to docker. One of the key differences is, that Singularity favours integration over isolation and comes with out of the box support for graphic accelerators and high-performance interconnects such as e.g. InfiniBand and Omni-Path.\n",
        "\n",
        "For example in singularity the systems user ids are by default not isolated from the containers user ids. The container instance usually just runs with the users privileges - in addition the home directory is also automatically mounted into the container instance.\n",
        "\n",
        "In 2021 open source project Singularity was renamed to **Apptainer**. The company Sylabs that provides commercial support as well as a community edition of singularity (SingularityCE) still uses the name **Singularity** for its products."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "892239e7-0a5f-44e7-a5f5-b5b8296fea9f",
      "metadata": {
        "tags": [],
        "id": "892239e7-0a5f-44e7-a5f5-b5b8296fea9f"
      },
      "source": [
        "### Singularity/Apptainer on VSC\n",
        "\n",
        "Both VSC-4 and VSC-5 come with the singularity packages already installed in the base system.\n",
        "\n",
        "At the beginning of 2023 the version that is in use is `Singularity 3.8.3`. The documentation for this specific version can be found here: https://apptainer.org/user-docs/3.8/\n",
        "\n",
        "A slightly newer version `3.8.5` is available in our module system (see `module avail singularity`) and we also provide multiple versions of apptainer (see `module avail apptainer`, currently `1.1.6` and `1.1.9` on VSC-4)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "748bc298",
      "metadata": {
        "tags": [],
        "id": "748bc298"
      },
      "source": [
        "### Build a singularity image from a definition file\n",
        "\n",
        "There are multiple ways to build a singularity image. If you want to customise an existing docker image or start your own custom image from scratch you can use a so called __definition file__ (`.def`) to describe what should end up in a container image.\n",
        "\n",
        "Definition files _can_ contain multiple sections such as `%files`, which simply describes files to copy into the container as well as `%test` to run automated tests after the container has been built. Please refer to the latest __[Apptainer documentation](https://apptainer.org/docs/user/latest/)__ for an in-depth description of possible sections and their purpose.\n",
        "\n",
        "```singularity\n",
        "Bootstrap: docker\n",
        "From: ubuntu:22.10\n",
        "\n",
        "%post\n",
        "    apt-get -y update\n",
        "    apt-get -y install cowsay lolcat\n",
        "\n",
        "%environment\n",
        "    export LC_ALL=C\n",
        "    export PATH=/usr/games:$PATH\n",
        "\n",
        "%runscript\n",
        "    date | cowsay | lolcat\n",
        "\n",
        "%test\n",
        "    grep -q NAME=\\\"Ubuntu\\\" /etc/os-release\n",
        "    if [ $? -eq 0 ]; then\n",
        "        echo \"Container base is Ubuntu as expected.\"\n",
        "    else\n",
        "        echo \"Container base is not Ubuntu.\"\n",
        "        exit 1\n",
        "    fi\n",
        "\n",
        "%help\n",
        "    This is a demo container used to illustrate a def file that uses all\n",
        "    supported sections.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d6e06a-0537-4ddb-bae4-7e1041c9d9d6",
      "metadata": {
        "id": "a7d6e06a-0537-4ddb-bae4-7e1041c9d9d6"
      },
      "source": [
        "Once the definition file has been saved you can then build the image by calling\n",
        "\n",
        "```bash\n",
        "$ sudo singularity build ./singularity/test.sif ./singularity/test.def\n",
        "```\n",
        "\n",
        "This will produce the image file `./singularity/test.sif`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b3f341-a554-409f-913c-025fa496598c",
      "metadata": {
        "id": "b7b3f341-a554-409f-913c-025fa496598c"
      },
      "source": [
        "To execute the test script after building the container you can run\n",
        "\n",
        "```bash\n",
        "$ sudo singularity test ./singularity/test.sif\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00499b5-651e-45f3-ac56-2157c55f999d",
      "metadata": {
        "id": "d00499b5-651e-45f3-ac56-2157c55f999d"
      },
      "source": [
        "Unfortunately it is necessary to either have elevated rights (e.g. via `sudo`) or a setup that allows a rootless run (e.g. fakeroot). Since VSC does not provide such an environment (yet) **it is not possible to build a singularity image on our cluster at the moment**.\n",
        "\n",
        "Thus the current recommendation is to build an image on your local machine and then upload it to VSC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38690d27",
      "metadata": {
        "tags": [],
        "id": "38690d27"
      },
      "source": [
        "### Build a singularity image from a docker image\n",
        "\n",
        "A very common use case is to just take an existing docker image and convert it into the singularity container format. Luckily this can be easily done by executing the following command\n",
        "\n",
        "```bash\n",
        "$ singularity build lolcow.sif docker://sylabsio/lolcow\n",
        "```\n",
        "\n",
        "<img src=\"images/development/singularity_build.png\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a5ecb2-030e-4feb-837b-7fa932e65b77",
      "metadata": {
        "tags": [],
        "id": "b6a5ecb2-030e-4feb-837b-7fa932e65b77"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/singularity\n",
        "singularity build lolcow.sif docker://sylabsio/lolcow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d2ff98e-9065-42fc-b03d-61a4fdd040c1",
      "metadata": {
        "tags": [],
        "id": "9d2ff98e-9065-42fc-b03d-61a4fdd040c1"
      },
      "source": [
        "### Run the image\n",
        "\n",
        "After the image has been built successfully, you can run a container instance (if it has a runscript) with\n",
        "\n",
        "```bash\n",
        "$ singularity run lolcow.sif\n",
        "```\n",
        "\n",
        "<img src=\"images/development/singularity_run.png\" width=\"400\">\n",
        "\n",
        "or execute a command in the container environment with\n",
        "\n",
        "```bash\n",
        "$ singularity exec lolcow.sif <command>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4ac656-ad48-482e-8ca1-6f037710c1bd",
      "metadata": {
        "tags": [],
        "id": "2a4ac656-ad48-482e-8ca1-6f037710c1bd"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/singularity\n",
        "singularity run lolcow.sif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c112e337-3a72-4afd-ae9e-f6140650591f",
      "metadata": {
        "tags": [],
        "id": "c112e337-3a72-4afd-ae9e-f6140650591f"
      },
      "outputs": [],
      "source": [
        "%%bash -e\n",
        "\n",
        "cd ./tooling/development/singularity\n",
        "singularity exec lolcow.sif ls -alh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24733d45-ef19-4d7c-8cb7-2e4fa8fe09fe",
      "metadata": {
        "tags": [],
        "id": "24733d45-ef19-4d7c-8cb7-2e4fa8fe09fe"
      },
      "outputs": [],
      "source": [
        "!rm ./tooling/development/singularity/lolcow.sif"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55b9e41",
      "metadata": {
        "tags": [],
        "id": "e55b9e41"
      },
      "source": [
        "## Development IDE's"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe82f9cc",
      "metadata": {
        "id": "fe82f9cc"
      },
      "source": [
        "### Visual Studio Code (Microsoft)\n",
        "\n",
        "At its core VS Code is 'just' a simple code editor. However lots of available extensions support the broad variety of use cases of this IDE. *Code* gained immensely in popularity in the past years and has a very active community. It is very well equipped to be used for developing and debugging many programming languages and is available for free on Windows, Mac & Linux (see __[Download Visual Studio Code](https://code.visualstudio.com/download)__).\n",
        "\n",
        "The recommended way to get started with VS Code & Python Development is to install the *Python* extension (see __[Python in VS Code](https://code.visualstudio.com/docs/languages/python)__) but you can also use e.g. the *Python Extension Pack* by Don Jayamanne which already contains a collection of interesting extensions.\n",
        "\n",
        "There are also a lot of other extensions to check out e.g.:\n",
        "* Remote Development Extension Pack - Remote development via e.g. SSH\n",
        "* Jupyter Extension Pack\n",
        "* Docker Extension Pack\n",
        "* Apptainer/Singularity\n",
        "* Git Extension Pack\n",
        "\n",
        "and many more ...\n",
        "\n",
        "With the extensions from the *Python Extension Pack* VS Code recognises python, venv, pipenv and even conda installations and lets the user select the right environment. It is also possible to run python programs interactively or debug them by using the integrated debugger UI, run scripts and manage code through your VCS.\n",
        "\n",
        "There is also an extensive article about data science usage of VS Code (see __[Data Science in Visual Studio Code](https://code.visualstudio.com/docs/datascience/overview)__).\n",
        "\n",
        "If you prefer a complete open source community-driven alternative to VS Code check out __[VSCodium](https://vscodium.com/)__\n",
        "\n",
        "<img src=\"images/development/vscode_debugging.png\" width=\"550\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f89497",
      "metadata": {
        "id": "38f89497"
      },
      "source": [
        "### PyCharm (JetBrains)\n",
        "\n",
        "PyCharm is a commercial product from JetBrains and compared to VS Code a ready to go all-in-one solution for python development. It is based on JetBrains IntelliJ IDEA Platform which was originally conceived for Java Development (see __[PyCharm by JetBrains](https://www.jetbrains.com/pycharm)__)\n",
        "\n",
        "In the beginning of 2023 it comes in two major editions:\n",
        "- Community: has all the main features (editor, debugger, refactoring, vcs support) and is free to use as well as open-source\n",
        "- Professional: has additional features for scientific python, web development and specific python frameworks as well as a profiler & remote development\n",
        "\n",
        "The IDE is known for its support and integration of tools as well as its refactoring and smart code navigation capabilities and is also available for Windows, Mac & Linux.\n",
        "\n",
        "There is also an option for educational/classroom licenses for students and academic staff (see __[Educational Licenses](https://www.jetbrains.com/community/education)__) - however it is explicitly stated that it may only be used for non-commercial and training purposes.\n",
        "\n",
        "Of course PyCharm also comes with its own plugin system and a marketplace, so it can be extended as well.\n",
        "\n",
        "Especially the builtin Scientific Mode (only available in the professional edition) and the Jupyter notebook support may be interesting because it allows the user to peak interactively into dataframes and also has a special tool for data plots (SciView).\n",
        "\n",
        "<img src=\"images/development/pycharm_scientific_mode.jpg\" width=\"550\">\n",
        "\n",
        "see __[Scientific mode tutorial](https://www.jetbrains.com/help/pycharm/matplotlib-tutorial.html#run)__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec36970-0fb7-4176-9fec-731fed800d2d",
      "metadata": {
        "id": "7ec36970-0fb7-4176-9fec-731fed800d2d"
      },
      "source": [
        "### Other IDE's\n",
        "\n",
        "There are also lots of other IDE's to check out that shouldn't go unmentioned as they are either very new or officially referred to in the official python FAQ (see __[Python IDE's for debugging](https://docs.python.org/3.10/faq/programming.html#is-there-a-source-code-level-debugger-with-breakpoints-single-stepping-etc)__)\n",
        "\n",
        "* __[JupyterLab Desktop](https://github.com/jupyterlab/jupyterlab-desktop)__\n",
        "* __[Spyder](https://www.spyder-ide.org/)__ (also part of the Anaconda distribution)\n",
        "* __[Wing Python IDE](https://wingware.com/)__\n",
        "* __[Komodo IDE](https://www.activestate.com/products/komodo-ide/)__"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7b25d2c9fa4339ca9c2d1c2c36fe6a22cc165ea5d14612a218506569477642ae"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}